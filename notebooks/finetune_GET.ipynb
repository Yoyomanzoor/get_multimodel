{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finetune GET Model on PBMC 10k Multiome\n",
        "\n",
        "This notebook demonstrates finetuning a GET model from a pretrained GET checkpoint (without diffusion).\n",
        "\n",
        "The checkpoint was generated using:\n",
        "- Script: `scripts/run_pretrain.py`\n",
        "- Config: `tutorials/yamls/pretrain_without_diffusion.yaml`\n",
        "- Model: GETRegionPretrain\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's import the necessary modules and set up our configuration.\n",
        "\n",
        "Note:\n",
        "If you run from a Mac, make sure you use the jupyter notebook rather than the VSCode interactive python editor as the later seems to have issue with multiple workers.\n",
        "If you run from Linux, both should work fine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add project root to Python path\n",
        "PROJECT_ROOT = \"/home/yoyomanzoor/Documents/get_multimodel\"\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "    os.chdir(PROJECT_ROOT)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from gcell.utils.causal_lib import get_subnet, plot_comm, preprocess_net\n",
        "\n",
        "from get_model.config.config import load_config, export_config, load_config_from_yaml\n",
        "from get_model.run_region import run_zarr as run\n",
        "\n",
        "yaml_path = \"get_model/config/finetune_GET_config.yaml\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using checkpoint: /home/yoyomanzoor/greatlakes/transformer-best-v1.ckpt\n"
          ]
        }
      ],
      "source": [
        "# Set up data paths\n",
        "data_dir = \"/home/yoyomanzoor/Crucial/get_data\"\n",
        "annotation_dir = data_dir + '/annotation_dir'\n",
        "\n",
        "# Checkpoint path\n",
        "checkpoint_path = os.path.expanduser(\"~/greatlakes/transformer-best-v1.ckpt\")\n",
        "print(f\"Using checkpoint: {checkpoint_path}\")\n",
        "assert Path(checkpoint_path).exists(), f\"Checkpoint not found at {checkpoint_path}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output path: /home/yoyomanzoor/Crucial/get_data/output/finetune_pbmc10k_multiome_GET/finetune_from_GET_checkpoint\n",
            "Training for 20 epochs\n",
            "Checkpoint: /home/yoyomanzoor/greatlakes/transformer-best-v1.ckpt\n"
          ]
        }
      ],
      "source": [
        "# Configure celltypes for modeling\n",
        "celltype_for_modeling = [\n",
        "    'memory_b',\n",
        "    'cd14_mono',\n",
        "    'gdt',\n",
        "    'cd8_tem_1',\n",
        "    'naive_b',\n",
        "    'mait',\n",
        "    'intermediate_b',\n",
        "    'cd4_naive',\n",
        "    'cd8_tem_2',\n",
        "    'cd8_naive',\n",
        "    'cd4_tem',\n",
        "    'cd4_tcm',\n",
        "    'cd16_mono',\n",
        "    'nk',\n",
        "    'cdc',\n",
        "    'treg'\n",
        "]\n",
        "\n",
        "# Load the predefined finetune tutorial config\n",
        "cfg = load_config('finetune_tutorial_pbmc')\n",
        "cfg.stage = 'fit'\n",
        "cfg.run.project_name = 'finetune_pbmc10k_multiome_GET'\n",
        "cfg.run.run_name = 'finetune_from_GET_checkpoint'\n",
        "cfg.dataset.quantitative_atac = False  # We use binary ATAC signal for motif interpretation analysis\n",
        "cfg.dataset.zarr_path = f\"{annotation_dir}/pbmc10k_multiome.zarr\"\n",
        "cfg.dataset.celltypes = ','.join(celltype_for_modeling)\n",
        "cfg.dataset.leave_out_celltypes = 'cd4_tcm'  # Leave out celltype for evaluation\n",
        "cfg.finetune.checkpoint = checkpoint_path\n",
        "cfg.training.epochs = 20\n",
        "cfg.machine.codebase = PROJECT_ROOT\n",
        "cfg.machine.num_devices = 1  # use 0 for cpu training; >=1 for gpu training\n",
        "cfg.machine.batch_size = 8  # batch size for training\n",
        "cfg.machine.output_dir = f\"{data_dir}/output\"\n",
        "\n",
        "print(f\"Output path: {cfg.machine.output_dir}/{cfg.run.project_name}/{cfg.run.run_name}\")\n",
        "print(f\"Training for {cfg.training.epochs} epochs\")\n",
        "print(f\"Checkpoint: {cfg.finetune.checkpoint}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration exported to get_model/config/finetune_GET_config.yaml\n"
          ]
        }
      ],
      "source": [
        "# Export the config to a yaml file\n",
        "export_config(cfg, yaml_path)\n",
        "print(f\"Configuration exported to {yaml_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the config from the yaml file\n",
        "cfg = load_config_from_yaml(yaml_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure finetune settings for loading pretrain checkpoint\n",
        "# The pretrain checkpoint (GETRegionPretrain) has head_mask, but finetune model (GETRegionFinetune) needs head_exp\n",
        "cfg.finetune.model_key = \"model\"  # Key for model in checkpoint (as set in run_pretrain.py)\n",
        "cfg.finetune.strict = False  # Allow missing head_exp weights (pretrain has head_mask instead)\n",
        "cfg.finetune.patterns_to_drop = [\"head_mask.\"]  # Drop head_mask weights (not used in finetune model)\n",
        "# Set rename_config to map pretrain checkpoint structure to finetune model structure\n",
        "if cfg.finetune.rename_config is None:\n",
        "    cfg.finetune.rename_config = {}\n",
        "# Ensure region_embed and encoder mappings are correct (if needed)\n",
        "cfg.finetune.rename_config.setdefault(\"encoder.region_embed\", \"region_embed\")\n",
        "cfg.finetune.rename_config.setdefault(\"region_embed.proj.\", \"region_embed.embed.\")\n",
        "cfg.finetune.rename_config.setdefault(\"encoder.cls_token\", \"cls_token\")\n",
        "\n",
        "print(f\"Finetune config:\")\n",
        "print(f\"  Model key: {cfg.finetune.model_key}\")\n",
        "print(f\"  Strict loading: {cfg.finetune.strict}\")\n",
        "print(f\"  Patterns to drop: {cfg.finetune.patterns_to_drop}\")\n",
        "print(f\"  Rename config: {cfg.finetune.rename_config}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Default checkpoint path is at: /home/yoyomanzoor/Crucial/get_data/output/finetune_pbmc10k_multiome_GET/finetune_from_GET_checkpoint/checkpoints/best.ckpt\n",
            "The `trainer.checkpoint_callback.best_model_path` variable will be updated to the checkpoint path after training\n"
          ]
        }
      ],
      "source": [
        "print(f\"Default checkpoint path is at: {cfg.machine.output_dir}/{cfg.run.project_name}/{cfg.run.run_name}/checkpoints/best.ckpt\")\n",
        "print(\"The `trainer.checkpoint_callback.best_model_path` variable will be updated to the checkpoint path after training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can start the finetuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yoyomanzoor/Crucial/get/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load ckpt from /home/yoyomanzoor/greatlakes/transformer-best-v1.ckpt\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for GETRegionFinetune:\n\tMissing key(s) in state_dict: \"cls_token\", \"region_embed.embed.weight\", \"region_embed.embed.bias\", \"encoder.blocks.0.norm1.weight\", \"encoder.blocks.0.norm1.bias\", \"encoder.blocks.0.attn.q_bias\", \"encoder.blocks.0.attn.v_bias\", \"encoder.blocks.0.attn.qkv.weight\", \"encoder.blocks.0.attn.proj.weight\", \"encoder.blocks.0.attn.proj.bias\", \"encoder.blocks.0.norm2.weight\", \"encoder.blocks.0.norm2.bias\", \"encoder.blocks.0.mlp.fc1.weight\", \"encoder.blocks.0.mlp.fc1.bias\", \"encoder.blocks.0.mlp.fc2.weight\", \"encoder.blocks.0.mlp.fc2.bias\", \"encoder.blocks.1.norm1.weight\", \"encoder.blocks.1.norm1.bias\", \"encoder.blocks.1.attn.q_bias\", \"encoder.blocks.1.attn.v_bias\", \"encoder.blocks.1.attn.qkv.weight\", \"encoder.blocks.1.attn.proj.weight\", \"encoder.blocks.1.attn.proj.bias\", \"encoder.blocks.1.norm2.weight\", \"encoder.blocks.1.norm2.bias\", \"encoder.blocks.1.mlp.fc1.weight\", \"encoder.blocks.1.mlp.fc1.bias\", \"encoder.blocks.1.mlp.fc2.weight\", \"encoder.blocks.1.mlp.fc2.bias\", \"encoder.blocks.2.norm1.weight\", \"encoder.blocks.2.norm1.bias\", \"encoder.blocks.2.attn.q_bias\", \"encoder.blocks.2.attn.v_bias\", \"encoder.blocks.2.attn.qkv.weight\", \"encoder.blocks.2.attn.proj.weight\", \"encoder.blocks.2.attn.proj.bias\", \"encoder.blocks.2.norm2.weight\", \"encoder.blocks.2.norm2.bias\", \"encoder.blocks.2.mlp.fc1.weight\", \"encoder.blocks.2.mlp.fc1.bias\", \"encoder.blocks.2.mlp.fc2.weight\", \"encoder.blocks.2.mlp.fc2.bias\", \"encoder.blocks.3.norm1.weight\", \"encoder.blocks.3.norm1.bias\", \"encoder.blocks.3.attn.q_bias\", \"encoder.blocks.3.attn.v_bias\", \"encoder.blocks.3.attn.qkv.weight\", \"encoder.blocks.3.attn.proj.weight\", \"encoder.blocks.3.attn.proj.bias\", \"encoder.blocks.3.norm2.weight\", \"encoder.blocks.3.norm2.bias\", \"encoder.blocks.3.mlp.fc1.weight\", \"encoder.blocks.3.mlp.fc1.bias\", \"encoder.blocks.3.mlp.fc2.weight\", \"encoder.blocks.3.mlp.fc2.bias\", \"encoder.blocks.4.norm1.weight\", \"encoder.blocks.4.norm1.bias\", \"encoder.blocks.4.attn.q_bias\", \"encoder.blocks.4.attn.v_bias\", \"encoder.blocks.4.attn.qkv.weight\", \"encoder.blocks.4.attn.proj.weight\", \"encoder.blocks.4.attn.proj.bias\", \"encoder.blocks.4.norm2.weight\", \"encoder.blocks.4.norm2.bias\", \"encoder.blocks.4.mlp.fc1.weight\", \"encoder.blocks.4.mlp.fc1.bias\", \"encoder.blocks.4.mlp.fc2.weight\", \"encoder.blocks.4.mlp.fc2.bias\", \"encoder.blocks.5.norm1.weight\", \"encoder.blocks.5.norm1.bias\", \"encoder.blocks.5.attn.q_bias\", \"encoder.blocks.5.attn.v_bias\", \"encoder.blocks.5.attn.qkv.weight\", \"encoder.blocks.5.attn.proj.weight\", \"encoder.blocks.5.attn.proj.bias\", \"encoder.blocks.5.norm2.weight\", \"encoder.blocks.5.norm2.bias\", \"encoder.blocks.5.mlp.fc1.weight\", \"encoder.blocks.5.mlp.fc1.bias\", \"encoder.blocks.5.mlp.fc2.weight\", \"encoder.blocks.5.mlp.fc2.bias\", \"encoder.blocks.6.norm1.weight\", \"encoder.blocks.6.norm1.bias\", \"encoder.blocks.6.attn.q_bias\", \"encoder.blocks.6.attn.v_bias\", \"encoder.blocks.6.attn.qkv.weight\", \"encoder.blocks.6.attn.proj.weight\", \"encoder.blocks.6.attn.proj.bias\", \"encoder.blocks.6.norm2.weight\", \"encoder.blocks.6.norm2.bias\", \"encoder.blocks.6.mlp.fc1.weight\", \"encoder.blocks.6.mlp.fc1.bias\", \"encoder.blocks.6.mlp.fc2.weight\", \"encoder.blocks.6.mlp.fc2.bias\", \"encoder.blocks.7.norm1.weight\", \"encoder.blocks.7.norm1.bias\", \"encoder.blocks.7.attn.q_bias\", \"encoder.blocks.7.attn.v_bias\", \"encoder.blocks.7.attn.qkv.weight\", \"encoder.blocks.7.attn.proj.weight\", \"encoder.blocks.7.attn.proj.bias\", \"encoder.blocks.7.norm2.weight\", \"encoder.blocks.7.norm2.bias\", \"encoder.blocks.7.mlp.fc1.weight\", \"encoder.blocks.7.mlp.fc1.bias\", \"encoder.blocks.7.mlp.fc2.weight\", \"encoder.blocks.7.mlp.fc2.bias\", \"encoder.blocks.8.norm1.weight\", \"encoder.blocks.8.norm1.bias\", \"encoder.blocks.8.attn.q_bias\", \"encoder.blocks.8.attn.v_bias\", \"encoder.blocks.8.attn.qkv.weight\", \"encoder.blocks.8.attn.proj.weight\", \"encoder.blocks.8.attn.proj.bias\", \"encoder.blocks.8.norm2.weight\", \"encoder.blocks.8.norm2.bias\", \"encoder.blocks.8.mlp.fc1.weight\", \"encoder.blocks.8.mlp.fc1.bias\", \"encoder.blocks.8.mlp.fc2.weight\", \"encoder.blocks.8.mlp.fc2.bias\", \"encoder.blocks.9.norm1.weight\", \"encoder.blocks.9.norm1.bias\", \"encoder.blocks.9.attn.q_bias\", \"encoder.blocks.9.attn.v_bias\", \"encoder.blocks.9.attn.qkv.weight\", \"encoder.blocks.9.attn.proj.weight\", \"encoder.blocks.9.attn.proj.bias\", \"encoder.blocks.9.norm2.weight\", \"encoder.blocks.9.norm2.bias\", \"encoder.blocks.9.mlp.fc1.weight\", \"encoder.blocks.9.mlp.fc1.bias\", \"encoder.blocks.9.mlp.fc2.weight\", \"encoder.blocks.9.mlp.fc2.bias\", \"encoder.blocks.10.norm1.weight\", \"encoder.blocks.10.norm1.bias\", \"encoder.blocks.10.attn.q_bias\", \"encoder.blocks.10.attn.v_bias\", \"encoder.blocks.10.attn.qkv.weight\", \"encoder.blocks.10.attn.proj.weight\", \"encoder.blocks.10.attn.proj.bias\", \"encoder.blocks.10.norm2.weight\", \"encoder.blocks.10.norm2.bias\", \"encoder.blocks.10.mlp.fc1.weight\", \"encoder.blocks.10.mlp.fc1.bias\", \"encoder.blocks.10.mlp.fc2.weight\", \"encoder.blocks.10.mlp.fc2.bias\", \"encoder.blocks.11.norm1.weight\", \"encoder.blocks.11.norm1.bias\", \"encoder.blocks.11.attn.q_bias\", \"encoder.blocks.11.attn.v_bias\", \"encoder.blocks.11.attn.qkv.weight\", \"encoder.blocks.11.attn.proj.weight\", \"encoder.blocks.11.attn.proj.bias\", \"encoder.blocks.11.norm2.weight\", \"encoder.blocks.11.norm2.bias\", \"encoder.blocks.11.mlp.fc1.weight\", \"encoder.blocks.11.mlp.fc1.bias\", \"encoder.blocks.11.mlp.fc2.weight\", \"encoder.blocks.11.mlp.fc2.bias\", \"encoder.norm.weight\", \"encoder.norm.bias\", \"head_exp.head.weight\", \"head_exp.head.bias\". \n\tUnexpected key(s) in state_dict: \"model.mask_token\", \"model.cls_token\", \"model.region_embed.embed.weight\", \"model.region_embed.embed.bias\", \"model.encoder.encoder.blocks.0.norm1.weight\", \"model.encoder.encoder.blocks.0.norm1.bias\", \"model.encoder.encoder.blocks.0.attn.q_bias\", \"model.encoder.encoder.blocks.0.attn.v_bias\", \"model.encoder.encoder.blocks.0.attn.qkv.weight\", \"model.encoder.encoder.blocks.0.attn.proj.weight\", \"model.encoder.encoder.blocks.0.attn.proj.bias\", \"model.encoder.encoder.blocks.0.norm2.weight\", \"model.encoder.encoder.blocks.0.norm2.bias\", \"model.encoder.encoder.blocks.0.mlp.fc1.weight\", \"model.encoder.encoder.blocks.0.mlp.fc1.bias\", \"model.encoder.encoder.blocks.0.mlp.fc2.weight\", \"model.encoder.encoder.blocks.0.mlp.fc2.bias\", \"model.encoder.encoder.blocks.1.norm1.weight\", \"model.encoder.encoder.blocks.1.norm1.bias\", \"model.encoder.encoder.blocks.1.attn.q_bias\", \"model.encoder.encoder.blocks.1.attn.v_bias\", \"model.encoder.encoder.blocks.1.attn.qkv.weight\", \"model.encoder.encoder.blocks.1.attn.proj.weight\", \"model.encoder.encoder.blocks.1.attn.proj.bias\", \"model.encoder.encoder.blocks.1.norm2.weight\", \"model.encoder.encoder.blocks.1.norm2.bias\", \"model.encoder.encoder.blocks.1.mlp.fc1.weight\", \"model.encoder.encoder.blocks.1.mlp.fc1.bias\", \"model.encoder.encoder.blocks.1.mlp.fc2.weight\", \"model.encoder.encoder.blocks.1.mlp.fc2.bias\", \"model.encoder.encoder.blocks.2.norm1.weight\", \"model.encoder.encoder.blocks.2.norm1.bias\", \"model.encoder.encoder.blocks.2.attn.q_bias\", \"model.encoder.encoder.blocks.2.attn.v_bias\", \"model.encoder.encoder.blocks.2.attn.qkv.weight\", \"model.encoder.encoder.blocks.2.attn.proj.weight\", \"model.encoder.encoder.blocks.2.attn.proj.bias\", \"model.encoder.encoder.blocks.2.norm2.weight\", \"model.encoder.encoder.blocks.2.norm2.bias\", \"model.encoder.encoder.blocks.2.mlp.fc1.weight\", \"model.encoder.encoder.blocks.2.mlp.fc1.bias\", \"model.encoder.encoder.blocks.2.mlp.fc2.weight\", \"model.encoder.encoder.blocks.2.mlp.fc2.bias\", \"model.encoder.encoder.blocks.3.norm1.weight\", \"model.encoder.encoder.blocks.3.norm1.bias\", \"model.encoder.encoder.blocks.3.attn.q_bias\", \"model.encoder.encoder.blocks.3.attn.v_bias\", \"model.encoder.encoder.blocks.3.attn.qkv.weight\", \"model.encoder.encoder.blocks.3.attn.proj.weight\", \"model.encoder.encoder.blocks.3.attn.proj.bias\", \"model.encoder.encoder.blocks.3.norm2.weight\", \"model.encoder.encoder.blocks.3.norm2.bias\", \"model.encoder.encoder.blocks.3.mlp.fc1.weight\", \"model.encoder.encoder.blocks.3.mlp.fc1.bias\", \"model.encoder.encoder.blocks.3.mlp.fc2.weight\", \"model.encoder.encoder.blocks.3.mlp.fc2.bias\", \"model.encoder.encoder.blocks.4.norm1.weight\", \"model.encoder.encoder.blocks.4.norm1.bias\", \"model.encoder.encoder.blocks.4.attn.q_bias\", \"model.encoder.encoder.blocks.4.attn.v_bias\", \"model.encoder.encoder.blocks.4.attn.qkv.weight\", \"model.encoder.encoder.blocks.4.attn.proj.weight\", \"model.encoder.encoder.blocks.4.attn.proj.bias\", \"model.encoder.encoder.blocks.4.norm2.weight\", \"model.encoder.encoder.blocks.4.norm2.bias\", \"model.encoder.encoder.blocks.4.mlp.fc1.weight\", \"model.encoder.encoder.blocks.4.mlp.fc1.bias\", \"model.encoder.encoder.blocks.4.mlp.fc2.weight\", \"model.encoder.encoder.blocks.4.mlp.fc2.bias\", \"model.encoder.encoder.blocks.5.norm1.weight\", \"model.encoder.encoder.blocks.5.norm1.bias\", \"model.encoder.encoder.blocks.5.attn.q_bias\", \"model.encoder.encoder.blocks.5.attn.v_bias\", \"model.encoder.encoder.blocks.5.attn.qkv.weight\", \"model.encoder.encoder.blocks.5.attn.proj.weight\", \"model.encoder.encoder.blocks.5.attn.proj.bias\", \"model.encoder.encoder.blocks.5.norm2.weight\", \"model.encoder.encoder.blocks.5.norm2.bias\", \"model.encoder.encoder.blocks.5.mlp.fc1.weight\", \"model.encoder.encoder.blocks.5.mlp.fc1.bias\", \"model.encoder.encoder.blocks.5.mlp.fc2.weight\", \"model.encoder.encoder.blocks.5.mlp.fc2.bias\", \"model.encoder.encoder.blocks.6.norm1.weight\", \"model.encoder.encoder.blocks.6.norm1.bias\", \"model.encoder.encoder.blocks.6.attn.q_bias\", \"model.encoder.encoder.blocks.6.attn.v_bias\", \"model.encoder.encoder.blocks.6.attn.qkv.weight\", \"model.encoder.encoder.blocks.6.attn.proj.weight\", \"model.encoder.encoder.blocks.6.attn.proj.bias\", \"model.encoder.encoder.blocks.6.norm2.weight\", \"model.encoder.encoder.blocks.6.norm2.bias\", \"model.encoder.encoder.blocks.6.mlp.fc1.weight\", \"model.encoder.encoder.blocks.6.mlp.fc1.bias\", \"model.encoder.encoder.blocks.6.mlp.fc2.weight\", \"model.encoder.encoder.blocks.6.mlp.fc2.bias\", \"model.encoder.encoder.blocks.7.norm1.weight\", \"model.encoder.encoder.blocks.7.norm1.bias\", \"model.encoder.encoder.blocks.7.attn.q_bias\", \"model.encoder.encoder.blocks.7.attn.v_bias\", \"model.encoder.encoder.blocks.7.attn.qkv.weight\", \"model.encoder.encoder.blocks.7.attn.proj.weight\", \"model.encoder.encoder.blocks.7.attn.proj.bias\", \"model.encoder.encoder.blocks.7.norm2.weight\", \"model.encoder.encoder.blocks.7.norm2.bias\", \"model.encoder.encoder.blocks.7.mlp.fc1.weight\", \"model.encoder.encoder.blocks.7.mlp.fc1.bias\", \"model.encoder.encoder.blocks.7.mlp.fc2.weight\", \"model.encoder.encoder.blocks.7.mlp.fc2.bias\", \"model.encoder.encoder.blocks.8.norm1.weight\", \"model.encoder.encoder.blocks.8.norm1.bias\", \"model.encoder.encoder.blocks.8.attn.q_bias\", \"model.encoder.encoder.blocks.8.attn.v_bias\", \"model.encoder.encoder.blocks.8.attn.qkv.weight\", \"model.encoder.encoder.blocks.8.attn.proj.weight\", \"model.encoder.encoder.blocks.8.attn.proj.bias\", \"model.encoder.encoder.blocks.8.norm2.weight\", \"model.encoder.encoder.blocks.8.norm2.bias\", \"model.encoder.encoder.blocks.8.mlp.fc1.weight\", \"model.encoder.encoder.blocks.8.mlp.fc1.bias\", \"model.encoder.encoder.blocks.8.mlp.fc2.weight\", \"model.encoder.encoder.blocks.8.mlp.fc2.bias\", \"model.encoder.encoder.blocks.9.norm1.weight\", \"model.encoder.encoder.blocks.9.norm1.bias\", \"model.encoder.encoder.blocks.9.attn.q_bias\", \"model.encoder.encoder.blocks.9.attn.v_bias\", \"model.encoder.encoder.blocks.9.attn.qkv.weight\", \"model.encoder.encoder.blocks.9.attn.proj.weight\", \"model.encoder.encoder.blocks.9.attn.proj.bias\", \"model.encoder.encoder.blocks.9.norm2.weight\", \"model.encoder.encoder.blocks.9.norm2.bias\", \"model.encoder.encoder.blocks.9.mlp.fc1.weight\", \"model.encoder.encoder.blocks.9.mlp.fc1.bias\", \"model.encoder.encoder.blocks.9.mlp.fc2.weight\", \"model.encoder.encoder.blocks.9.mlp.fc2.bias\", \"model.encoder.encoder.blocks.10.norm1.weight\", \"model.encoder.encoder.blocks.10.norm1.bias\", \"model.encoder.encoder.blocks.10.attn.q_bias\", \"model.encoder.encoder.blocks.10.attn.v_bias\", \"model.encoder.encoder.blocks.10.attn.qkv.weight\", \"model.encoder.encoder.blocks.10.attn.proj.weight\", \"model.encoder.encoder.blocks.10.attn.proj.bias\", \"model.encoder.encoder.blocks.10.norm2.weight\", \"model.encoder.encoder.blocks.10.norm2.bias\", \"model.encoder.encoder.blocks.10.mlp.fc1.weight\", \"model.encoder.encoder.blocks.10.mlp.fc1.bias\", \"model.encoder.encoder.blocks.10.mlp.fc2.weight\", \"model.encoder.encoder.blocks.10.mlp.fc2.bias\", \"model.encoder.encoder.blocks.11.norm1.weight\", \"model.encoder.encoder.blocks.11.norm1.bias\", \"model.encoder.encoder.blocks.11.attn.q_bias\", \"model.encoder.encoder.blocks.11.attn.v_bias\", \"model.encoder.encoder.blocks.11.attn.qkv.weight\", \"model.encoder.encoder.blocks.11.attn.proj.weight\", \"model.encoder.encoder.blocks.11.attn.proj.bias\", \"model.encoder.encoder.blocks.11.norm2.weight\", \"model.encoder.encoder.blocks.11.norm2.bias\", \"model.encoder.encoder.blocks.11.mlp.fc1.weight\", \"model.encoder.encoder.blocks.11.mlp.fc1.bias\", \"model.encoder.encoder.blocks.11.mlp.fc2.weight\", \"model.encoder.encoder.blocks.11.mlp.fc2.bias\", \"model.encoder.norm.weight\", \"model.encoder.norm.bias\", \"model.head_mask.weight\", \"model.head_mask.bias\". ",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the finetuning\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m trainer = \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCheckpoint path:\u001b[39m\u001b[33m\"\u001b[39m, trainer.checkpoint_callback.best_model_path)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/get_multimodel/get_model/run_region.py:433\u001b[39m, in \u001b[36mrun_zarr\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_zarr\u001b[39m(cfg: DictConfig):\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     model = \u001b[43mRegionLitModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m     logging.debug(OmegaConf.to_yaml(cfg))\n\u001b[32m    435\u001b[39m     dm = RegionZarrDataModule(cfg)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/get_multimodel/get_model/run_region.py:119\u001b[39m, in \u001b[36mRegionLitModel.__init__\u001b[39m\u001b[34m(self, cfg)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: DictConfig):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/get_multimodel/get_model/run.py:107\u001b[39m, in \u001b[36mLitModel.__init__\u001b[39m\u001b[34m(self, cfg)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    106\u001b[39m \u001b[38;5;28mself\u001b[39m.cfg = cfg\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28mself\u001b[39m.loss = \u001b[38;5;28mself\u001b[39m.model.loss\n\u001b[32m    109\u001b[39m \u001b[38;5;28mself\u001b[39m.metrics = \u001b[38;5;28mself\u001b[39m.model.metrics\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/get_multimodel/get_model/run_region.py:349\u001b[39m, in \u001b[36mRegionLitModel.get_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    343\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mlora\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m checkpoint_model.keys())\n\u001b[32m    344\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.finetune.use_lora\n\u001b[32m    345\u001b[39m ):\n\u001b[32m    346\u001b[39m     logging.info(\n\u001b[32m    347\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mModel checkpoint does not contain LoRA parameters but use_lora is set to True, using the checkpoint as base model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    348\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m     \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinetune\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrict\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m     add_lora_by_name(model, \u001b[38;5;28mself\u001b[39m.cfg.finetune.layers_with_lora, lora_config)\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/get_multimodel/get_model/utils.py:227\u001b[39m, in \u001b[36mload_state_dict\u001b[39m\u001b[34m(model, state_dict, strict, patterns_to_drop)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns_to_drop:\n\u001b[32m    226\u001b[39m     state_dict = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m state_dict.items() \u001b[38;5;28;01mif\u001b[39;00m pattern \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k}\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Crucial/get/lib/python3.12/site-packages/torch/nn/modules/module.py:2584\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2576\u001b[39m         error_msgs.insert(\n\u001b[32m   2577\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2578\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2579\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2580\u001b[39m             ),\n\u001b[32m   2581\u001b[39m         )\n\u001b[32m   2583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2586\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2587\u001b[39m         )\n\u001b[32m   2588\u001b[39m     )\n\u001b[32m   2589\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for GETRegionFinetune:\n\tMissing key(s) in state_dict: \"cls_token\", \"region_embed.embed.weight\", \"region_embed.embed.bias\", \"encoder.blocks.0.norm1.weight\", \"encoder.blocks.0.norm1.bias\", \"encoder.blocks.0.attn.q_bias\", \"encoder.blocks.0.attn.v_bias\", \"encoder.blocks.0.attn.qkv.weight\", \"encoder.blocks.0.attn.proj.weight\", \"encoder.blocks.0.attn.proj.bias\", \"encoder.blocks.0.norm2.weight\", \"encoder.blocks.0.norm2.bias\", \"encoder.blocks.0.mlp.fc1.weight\", \"encoder.blocks.0.mlp.fc1.bias\", \"encoder.blocks.0.mlp.fc2.weight\", \"encoder.blocks.0.mlp.fc2.bias\", \"encoder.blocks.1.norm1.weight\", \"encoder.blocks.1.norm1.bias\", \"encoder.blocks.1.attn.q_bias\", \"encoder.blocks.1.attn.v_bias\", \"encoder.blocks.1.attn.qkv.weight\", \"encoder.blocks.1.attn.proj.weight\", \"encoder.blocks.1.attn.proj.bias\", \"encoder.blocks.1.norm2.weight\", \"encoder.blocks.1.norm2.bias\", \"encoder.blocks.1.mlp.fc1.weight\", \"encoder.blocks.1.mlp.fc1.bias\", \"encoder.blocks.1.mlp.fc2.weight\", \"encoder.blocks.1.mlp.fc2.bias\", \"encoder.blocks.2.norm1.weight\", \"encoder.blocks.2.norm1.bias\", \"encoder.blocks.2.attn.q_bias\", \"encoder.blocks.2.attn.v_bias\", \"encoder.blocks.2.attn.qkv.weight\", \"encoder.blocks.2.attn.proj.weight\", \"encoder.blocks.2.attn.proj.bias\", \"encoder.blocks.2.norm2.weight\", \"encoder.blocks.2.norm2.bias\", \"encoder.blocks.2.mlp.fc1.weight\", \"encoder.blocks.2.mlp.fc1.bias\", \"encoder.blocks.2.mlp.fc2.weight\", \"encoder.blocks.2.mlp.fc2.bias\", \"encoder.blocks.3.norm1.weight\", \"encoder.blocks.3.norm1.bias\", \"encoder.blocks.3.attn.q_bias\", \"encoder.blocks.3.attn.v_bias\", \"encoder.blocks.3.attn.qkv.weight\", \"encoder.blocks.3.attn.proj.weight\", \"encoder.blocks.3.attn.proj.bias\", \"encoder.blocks.3.norm2.weight\", \"encoder.blocks.3.norm2.bias\", \"encoder.blocks.3.mlp.fc1.weight\", \"encoder.blocks.3.mlp.fc1.bias\", \"encoder.blocks.3.mlp.fc2.weight\", \"encoder.blocks.3.mlp.fc2.bias\", \"encoder.blocks.4.norm1.weight\", \"encoder.blocks.4.norm1.bias\", \"encoder.blocks.4.attn.q_bias\", \"encoder.blocks.4.attn.v_bias\", \"encoder.blocks.4.attn.qkv.weight\", \"encoder.blocks.4.attn.proj.weight\", \"encoder.blocks.4.attn.proj.bias\", \"encoder.blocks.4.norm2.weight\", \"encoder.blocks.4.norm2.bias\", \"encoder.blocks.4.mlp.fc1.weight\", \"encoder.blocks.4.mlp.fc1.bias\", \"encoder.blocks.4.mlp.fc2.weight\", \"encoder.blocks.4.mlp.fc2.bias\", \"encoder.blocks.5.norm1.weight\", \"encoder.blocks.5.norm1.bias\", \"encoder.blocks.5.attn.q_bias\", \"encoder.blocks.5.attn.v_bias\", \"encoder.blocks.5.attn.qkv.weight\", \"encoder.blocks.5.attn.proj.weight\", \"encoder.blocks.5.attn.proj.bias\", \"encoder.blocks.5.norm2.weight\", \"encoder.blocks.5.norm2.bias\", \"encoder.blocks.5.mlp.fc1.weight\", \"encoder.blocks.5.mlp.fc1.bias\", \"encoder.blocks.5.mlp.fc2.weight\", \"encoder.blocks.5.mlp.fc2.bias\", \"encoder.blocks.6.norm1.weight\", \"encoder.blocks.6.norm1.bias\", \"encoder.blocks.6.attn.q_bias\", \"encoder.blocks.6.attn.v_bias\", \"encoder.blocks.6.attn.qkv.weight\", \"encoder.blocks.6.attn.proj.weight\", \"encoder.blocks.6.attn.proj.bias\", \"encoder.blocks.6.norm2.weight\", \"encoder.blocks.6.norm2.bias\", \"encoder.blocks.6.mlp.fc1.weight\", \"encoder.blocks.6.mlp.fc1.bias\", \"encoder.blocks.6.mlp.fc2.weight\", \"encoder.blocks.6.mlp.fc2.bias\", \"encoder.blocks.7.norm1.weight\", \"encoder.blocks.7.norm1.bias\", \"encoder.blocks.7.attn.q_bias\", \"encoder.blocks.7.attn.v_bias\", \"encoder.blocks.7.attn.qkv.weight\", \"encoder.blocks.7.attn.proj.weight\", \"encoder.blocks.7.attn.proj.bias\", \"encoder.blocks.7.norm2.weight\", \"encoder.blocks.7.norm2.bias\", \"encoder.blocks.7.mlp.fc1.weight\", \"encoder.blocks.7.mlp.fc1.bias\", \"encoder.blocks.7.mlp.fc2.weight\", \"encoder.blocks.7.mlp.fc2.bias\", \"encoder.blocks.8.norm1.weight\", \"encoder.blocks.8.norm1.bias\", \"encoder.blocks.8.attn.q_bias\", \"encoder.blocks.8.attn.v_bias\", \"encoder.blocks.8.attn.qkv.weight\", \"encoder.blocks.8.attn.proj.weight\", \"encoder.blocks.8.attn.proj.bias\", \"encoder.blocks.8.norm2.weight\", \"encoder.blocks.8.norm2.bias\", \"encoder.blocks.8.mlp.fc1.weight\", \"encoder.blocks.8.mlp.fc1.bias\", \"encoder.blocks.8.mlp.fc2.weight\", \"encoder.blocks.8.mlp.fc2.bias\", \"encoder.blocks.9.norm1.weight\", \"encoder.blocks.9.norm1.bias\", \"encoder.blocks.9.attn.q_bias\", \"encoder.blocks.9.attn.v_bias\", \"encoder.blocks.9.attn.qkv.weight\", \"encoder.blocks.9.attn.proj.weight\", \"encoder.blocks.9.attn.proj.bias\", \"encoder.blocks.9.norm2.weight\", \"encoder.blocks.9.norm2.bias\", \"encoder.blocks.9.mlp.fc1.weight\", \"encoder.blocks.9.mlp.fc1.bias\", \"encoder.blocks.9.mlp.fc2.weight\", \"encoder.blocks.9.mlp.fc2.bias\", \"encoder.blocks.10.norm1.weight\", \"encoder.blocks.10.norm1.bias\", \"encoder.blocks.10.attn.q_bias\", \"encoder.blocks.10.attn.v_bias\", \"encoder.blocks.10.attn.qkv.weight\", \"encoder.blocks.10.attn.proj.weight\", \"encoder.blocks.10.attn.proj.bias\", \"encoder.blocks.10.norm2.weight\", \"encoder.blocks.10.norm2.bias\", \"encoder.blocks.10.mlp.fc1.weight\", \"encoder.blocks.10.mlp.fc1.bias\", \"encoder.blocks.10.mlp.fc2.weight\", \"encoder.blocks.10.mlp.fc2.bias\", \"encoder.blocks.11.norm1.weight\", \"encoder.blocks.11.norm1.bias\", \"encoder.blocks.11.attn.q_bias\", \"encoder.blocks.11.attn.v_bias\", \"encoder.blocks.11.attn.qkv.weight\", \"encoder.blocks.11.attn.proj.weight\", \"encoder.blocks.11.attn.proj.bias\", \"encoder.blocks.11.norm2.weight\", \"encoder.blocks.11.norm2.bias\", \"encoder.blocks.11.mlp.fc1.weight\", \"encoder.blocks.11.mlp.fc1.bias\", \"encoder.blocks.11.mlp.fc2.weight\", \"encoder.blocks.11.mlp.fc2.bias\", \"encoder.norm.weight\", \"encoder.norm.bias\", \"head_exp.head.weight\", \"head_exp.head.bias\". \n\tUnexpected key(s) in state_dict: \"model.mask_token\", \"model.cls_token\", \"model.region_embed.embed.weight\", \"model.region_embed.embed.bias\", \"model.encoder.encoder.blocks.0.norm1.weight\", \"model.encoder.encoder.blocks.0.norm1.bias\", \"model.encoder.encoder.blocks.0.attn.q_bias\", \"model.encoder.encoder.blocks.0.attn.v_bias\", \"model.encoder.encoder.blocks.0.attn.qkv.weight\", \"model.encoder.encoder.blocks.0.attn.proj.weight\", \"model.encoder.encoder.blocks.0.attn.proj.bias\", \"model.encoder.encoder.blocks.0.norm2.weight\", \"model.encoder.encoder.blocks.0.norm2.bias\", \"model.encoder.encoder.blocks.0.mlp.fc1.weight\", \"model.encoder.encoder.blocks.0.mlp.fc1.bias\", \"model.encoder.encoder.blocks.0.mlp.fc2.weight\", \"model.encoder.encoder.blocks.0.mlp.fc2.bias\", \"model.encoder.encoder.blocks.1.norm1.weight\", \"model.encoder.encoder.blocks.1.norm1.bias\", \"model.encoder.encoder.blocks.1.attn.q_bias\", \"model.encoder.encoder.blocks.1.attn.v_bias\", \"model.encoder.encoder.blocks.1.attn.qkv.weight\", \"model.encoder.encoder.blocks.1.attn.proj.weight\", \"model.encoder.encoder.blocks.1.attn.proj.bias\", \"model.encoder.encoder.blocks.1.norm2.weight\", \"model.encoder.encoder.blocks.1.norm2.bias\", \"model.encoder.encoder.blocks.1.mlp.fc1.weight\", \"model.encoder.encoder.blocks.1.mlp.fc1.bias\", \"model.encoder.encoder.blocks.1.mlp.fc2.weight\", \"model.encoder.encoder.blocks.1.mlp.fc2.bias\", \"model.encoder.encoder.blocks.2.norm1.weight\", \"model.encoder.encoder.blocks.2.norm1.bias\", \"model.encoder.encoder.blocks.2.attn.q_bias\", \"model.encoder.encoder.blocks.2.attn.v_bias\", \"model.encoder.encoder.blocks.2.attn.qkv.weight\", \"model.encoder.encoder.blocks.2.attn.proj.weight\", \"model.encoder.encoder.blocks.2.attn.proj.bias\", \"model.encoder.encoder.blocks.2.norm2.weight\", \"model.encoder.encoder.blocks.2.norm2.bias\", \"model.encoder.encoder.blocks.2.mlp.fc1.weight\", \"model.encoder.encoder.blocks.2.mlp.fc1.bias\", \"model.encoder.encoder.blocks.2.mlp.fc2.weight\", \"model.encoder.encoder.blocks.2.mlp.fc2.bias\", \"model.encoder.encoder.blocks.3.norm1.weight\", \"model.encoder.encoder.blocks.3.norm1.bias\", \"model.encoder.encoder.blocks.3.attn.q_bias\", \"model.encoder.encoder.blocks.3.attn.v_bias\", \"model.encoder.encoder.blocks.3.attn.qkv.weight\", \"model.encoder.encoder.blocks.3.attn.proj.weight\", \"model.encoder.encoder.blocks.3.attn.proj.bias\", \"model.encoder.encoder.blocks.3.norm2.weight\", \"model.encoder.encoder.blocks.3.norm2.bias\", \"model.encoder.encoder.blocks.3.mlp.fc1.weight\", \"model.encoder.encoder.blocks.3.mlp.fc1.bias\", \"model.encoder.encoder.blocks.3.mlp.fc2.weight\", \"model.encoder.encoder.blocks.3.mlp.fc2.bias\", \"model.encoder.encoder.blocks.4.norm1.weight\", \"model.encoder.encoder.blocks.4.norm1.bias\", \"model.encoder.encoder.blocks.4.attn.q_bias\", \"model.encoder.encoder.blocks.4.attn.v_bias\", \"model.encoder.encoder.blocks.4.attn.qkv.weight\", \"model.encoder.encoder.blocks.4.attn.proj.weight\", \"model.encoder.encoder.blocks.4.attn.proj.bias\", \"model.encoder.encoder.blocks.4.norm2.weight\", \"model.encoder.encoder.blocks.4.norm2.bias\", \"model.encoder.encoder.blocks.4.mlp.fc1.weight\", \"model.encoder.encoder.blocks.4.mlp.fc1.bias\", \"model.encoder.encoder.blocks.4.mlp.fc2.weight\", \"model.encoder.encoder.blocks.4.mlp.fc2.bias\", \"model.encoder.encoder.blocks.5.norm1.weight\", \"model.encoder.encoder.blocks.5.norm1.bias\", \"model.encoder.encoder.blocks.5.attn.q_bias\", \"model.encoder.encoder.blocks.5.attn.v_bias\", \"model.encoder.encoder.blocks.5.attn.qkv.weight\", \"model.encoder.encoder.blocks.5.attn.proj.weight\", \"model.encoder.encoder.blocks.5.attn.proj.bias\", \"model.encoder.encoder.blocks.5.norm2.weight\", \"model.encoder.encoder.blocks.5.norm2.bias\", \"model.encoder.encoder.blocks.5.mlp.fc1.weight\", \"model.encoder.encoder.blocks.5.mlp.fc1.bias\", \"model.encoder.encoder.blocks.5.mlp.fc2.weight\", \"model.encoder.encoder.blocks.5.mlp.fc2.bias\", \"model.encoder.encoder.blocks.6.norm1.weight\", \"model.encoder.encoder.blocks.6.norm1.bias\", \"model.encoder.encoder.blocks.6.attn.q_bias\", \"model.encoder.encoder.blocks.6.attn.v_bias\", \"model.encoder.encoder.blocks.6.attn.qkv.weight\", \"model.encoder.encoder.blocks.6.attn.proj.weight\", \"model.encoder.encoder.blocks.6.attn.proj.bias\", \"model.encoder.encoder.blocks.6.norm2.weight\", \"model.encoder.encoder.blocks.6.norm2.bias\", \"model.encoder.encoder.blocks.6.mlp.fc1.weight\", \"model.encoder.encoder.blocks.6.mlp.fc1.bias\", \"model.encoder.encoder.blocks.6.mlp.fc2.weight\", \"model.encoder.encoder.blocks.6.mlp.fc2.bias\", \"model.encoder.encoder.blocks.7.norm1.weight\", \"model.encoder.encoder.blocks.7.norm1.bias\", \"model.encoder.encoder.blocks.7.attn.q_bias\", \"model.encoder.encoder.blocks.7.attn.v_bias\", \"model.encoder.encoder.blocks.7.attn.qkv.weight\", \"model.encoder.encoder.blocks.7.attn.proj.weight\", \"model.encoder.encoder.blocks.7.attn.proj.bias\", \"model.encoder.encoder.blocks.7.norm2.weight\", \"model.encoder.encoder.blocks.7.norm2.bias\", \"model.encoder.encoder.blocks.7.mlp.fc1.weight\", \"model.encoder.encoder.blocks.7.mlp.fc1.bias\", \"model.encoder.encoder.blocks.7.mlp.fc2.weight\", \"model.encoder.encoder.blocks.7.mlp.fc2.bias\", \"model.encoder.encoder.blocks.8.norm1.weight\", \"model.encoder.encoder.blocks.8.norm1.bias\", \"model.encoder.encoder.blocks.8.attn.q_bias\", \"model.encoder.encoder.blocks.8.attn.v_bias\", \"model.encoder.encoder.blocks.8.attn.qkv.weight\", \"model.encoder.encoder.blocks.8.attn.proj.weight\", \"model.encoder.encoder.blocks.8.attn.proj.bias\", \"model.encoder.encoder.blocks.8.norm2.weight\", \"model.encoder.encoder.blocks.8.norm2.bias\", \"model.encoder.encoder.blocks.8.mlp.fc1.weight\", \"model.encoder.encoder.blocks.8.mlp.fc1.bias\", \"model.encoder.encoder.blocks.8.mlp.fc2.weight\", \"model.encoder.encoder.blocks.8.mlp.fc2.bias\", \"model.encoder.encoder.blocks.9.norm1.weight\", \"model.encoder.encoder.blocks.9.norm1.bias\", \"model.encoder.encoder.blocks.9.attn.q_bias\", \"model.encoder.encoder.blocks.9.attn.v_bias\", \"model.encoder.encoder.blocks.9.attn.qkv.weight\", \"model.encoder.encoder.blocks.9.attn.proj.weight\", \"model.encoder.encoder.blocks.9.attn.proj.bias\", \"model.encoder.encoder.blocks.9.norm2.weight\", \"model.encoder.encoder.blocks.9.norm2.bias\", \"model.encoder.encoder.blocks.9.mlp.fc1.weight\", \"model.encoder.encoder.blocks.9.mlp.fc1.bias\", \"model.encoder.encoder.blocks.9.mlp.fc2.weight\", \"model.encoder.encoder.blocks.9.mlp.fc2.bias\", \"model.encoder.encoder.blocks.10.norm1.weight\", \"model.encoder.encoder.blocks.10.norm1.bias\", \"model.encoder.encoder.blocks.10.attn.q_bias\", \"model.encoder.encoder.blocks.10.attn.v_bias\", \"model.encoder.encoder.blocks.10.attn.qkv.weight\", \"model.encoder.encoder.blocks.10.attn.proj.weight\", \"model.encoder.encoder.blocks.10.attn.proj.bias\", \"model.encoder.encoder.blocks.10.norm2.weight\", \"model.encoder.encoder.blocks.10.norm2.bias\", \"model.encoder.encoder.blocks.10.mlp.fc1.weight\", \"model.encoder.encoder.blocks.10.mlp.fc1.bias\", \"model.encoder.encoder.blocks.10.mlp.fc2.weight\", \"model.encoder.encoder.blocks.10.mlp.fc2.bias\", \"model.encoder.encoder.blocks.11.norm1.weight\", \"model.encoder.encoder.blocks.11.norm1.bias\", \"model.encoder.encoder.blocks.11.attn.q_bias\", \"model.encoder.encoder.blocks.11.attn.v_bias\", \"model.encoder.encoder.blocks.11.attn.qkv.weight\", \"model.encoder.encoder.blocks.11.attn.proj.weight\", \"model.encoder.encoder.blocks.11.attn.proj.bias\", \"model.encoder.encoder.blocks.11.norm2.weight\", \"model.encoder.encoder.blocks.11.norm2.bias\", \"model.encoder.encoder.blocks.11.mlp.fc1.weight\", \"model.encoder.encoder.blocks.11.mlp.fc1.bias\", \"model.encoder.encoder.blocks.11.mlp.fc2.weight\", \"model.encoder.encoder.blocks.11.mlp.fc2.bias\", \"model.encoder.norm.weight\", \"model.encoder.norm.bias\", \"model.head_mask.weight\", \"model.head_mask.bias\". "
          ]
        }
      ],
      "source": [
        "# Run the finetuning\n",
        "trainer = run(cfg)\n",
        "print(\"Checkpoint path:\", trainer.checkpoint_callback.best_model_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
