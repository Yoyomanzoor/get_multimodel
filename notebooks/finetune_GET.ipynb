{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finetune GET Model on PBMC 10k Multiome\n",
        "\n",
        "This notebook demonstrates finetuning a GET model from a pretrained GET checkpoint (without diffusion).\n",
        "\n",
        "The checkpoint was generated using:\n",
        "- Script: `scripts/run_pretrain.py`\n",
        "- Config: `tutorials/yamls/pretrain_without_diffusion.yaml`\n",
        "- Model: GETRegionPretrain\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's import the necessary modules and set up our configuration.\n",
        "\n",
        "Note:\n",
        "If you run from a Mac, make sure you use the jupyter notebook rather than the VSCode interactive python editor as the later seems to have issue with multiple workers.\n",
        "If you run from Linux, both should work fine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yoyomanzoor/micromamba/envs/get/lib/python3.12/site-packages/seqlogo/seqlogo.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "/home/yoyomanzoor/micromamba/envs/get/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add project root to Python path\n",
        "PROJECT_ROOT = \"/home/yoyomanzoor/Documents/get_multimodel\"\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "    os.chdir(PROJECT_ROOT)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from gcell.utils.causal_lib import get_subnet, plot_comm, preprocess_net\n",
        "\n",
        "from get_model.config.config import load_config, export_config, load_config_from_yaml\n",
        "from get_model.run_region import run_zarr as run\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using checkpoint: /home/yoyomanzoor/greatlakes/GET.ckpt\n"
          ]
        }
      ],
      "source": [
        "# Set up data paths\n",
        "data_dir = \"/scratch/bioinf593f25_class_root/bioinf593f25_class/shared_data/themanifolds/tutorial_data\"\n",
        "annotation_dir = data_dir + '/annotation_dir'\n",
        "\n",
        "# Checkpoint path\n",
        "checkpoint_path = os.path.expanduser(\"~/greatlakes/GET.ckpt\")\n",
        "print(f\"Using checkpoint: {checkpoint_path}\")\n",
        "assert Path(checkpoint_path).exists(), f\"Checkpoint not found at {checkpoint_path}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output path: /scratch/bioinf593f25_class_root/bioinf593f25_class/shared_data/themanifolds/tutorial_data/output/finetune_pbmc10k_multiome_GET/finetune_from_GET_checkpoint\n",
            "Training for 20 epochs\n",
            "Checkpoint: /home/yoyomanzoor/greatlakes/GET.ckpt\n"
          ]
        }
      ],
      "source": [
        "# Configure celltypes for modeling\n",
        "celltype_for_modeling = [\n",
        "    'memory_b',\n",
        "    'cd14_mono',\n",
        "    'gdt',\n",
        "    'cd8_tem_1',\n",
        "    'naive_b',\n",
        "    'mait',\n",
        "    'intermediate_b',\n",
        "    'cd4_naive',\n",
        "    'cd8_tem_2',\n",
        "    'cd8_naive',\n",
        "    'cd4_tem',\n",
        "    'cd4_tcm',\n",
        "    'cd16_mono',\n",
        "    'nk',\n",
        "    'cdc',\n",
        "    'treg'\n",
        "]\n",
        "\n",
        "# Load the predefined finetune tutorial config\n",
        "cfg = load_config('finetune_tutorial_pbmc')\n",
        "cfg.stage = 'fit'\n",
        "cfg.run.project_name = 'finetune_pbmc10k_multiome_GET'\n",
        "cfg.run.run_name = 'finetune_from_GET_checkpoint'\n",
        "cfg.dataset.quantitative_atac = False  # We use binary ATAC signal for motif interpretation analysis\n",
        "cfg.dataset.zarr_path = f\"{annotation_dir}/pbmc10k_multiome.zarr\"\n",
        "cfg.dataset.celltypes = ','.join(celltype_for_modeling)\n",
        "cfg.dataset.leave_out_celltypes = 'cd4_tcm'  # Leave out celltype for evaluation\n",
        "cfg.finetune.checkpoint = checkpoint_path\n",
        "cfg.training.epochs = 20\n",
        "cfg.machine.codebase = PROJECT_ROOT\n",
        "cfg.machine.num_devices = 1  # use 0 for cpu training; >=1 for gpu training\n",
        "cfg.machine.batch_size = 8  # batch size for training\n",
        "cfg.machine.output_dir = f\"{data_dir}/output\"\n",
        "\n",
        "print(f\"Output path: {cfg.machine.output_dir}/{cfg.run.project_name}/{cfg.run.run_name}\")\n",
        "print(f\"Training for {cfg.training.epochs} epochs\")\n",
        "print(f\"Checkpoint: {cfg.finetune.checkpoint}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the config to a yaml file\n",
        "export_config(cfg, \"exported_finetune_GET_config.yaml\")\n",
        "print(\"Configuration exported to exported_finetune_GET_config.yaml\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the config from the yaml file\n",
        "cfg = load_config_from_yaml(\"exported_finetune_GET_config.yaml\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Default checkpoint path is at: {cfg.machine.output_dir}/{cfg.run.project_name}/{cfg.run.run_name}/checkpoints/best.ckpt\")\n",
        "print(\"The `trainer.checkpoint_callback.best_model_path` variable will be updated to the checkpoint path after training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can start the finetuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the finetuning\n",
        "trainer = run(cfg)\n",
        "print(\"Checkpoint path:\", trainer.checkpoint_callback.best_model_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
