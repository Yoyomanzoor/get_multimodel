{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finetune GETDiffusion Model on PBMC 10k Multiome\n",
        "\n",
        "This notebook demonstrates finetuning a GET model from a pretrained GETDiffusion checkpoint (with diffusion).\n",
        "\n",
        "The checkpoint was generated using:\n",
        "- Script: `scripts/run_diffusion-transformer.py`\n",
        "- Config: `tutorials/yamls/pretrain_with_diffusion-transfomer.yaml`\n",
        "- Model: GETRegionDiffusion\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's import the necessary modules and set up our configuration.\n",
        "\n",
        "Note:\n",
        "If you run from a Mac, make sure you use the jupyter notebook rather than the VSCode interactive python editor as the later seems to have issue with multiple workers.\n",
        "If you run from Linux, both should work fine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add project root to Python path\n",
        "PROJECT_ROOT = \"/home/yoyomanzoor/Documents/get_multimodel\"\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "    os.chdir(PROJECT_ROOT)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from gcell.utils.causal_lib import get_subnet, plot_comm, preprocess_net\n",
        "\n",
        "from get_model.config.config import load_config, export_config, load_config_from_yaml\n",
        "from get_model.run_region import run_zarr as run\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finetune Configuration\n",
        "\n",
        "We'll start by loading a predefined configuration and customizing it for our needs.\n",
        "\n",
        "The base configuration is in `get_model/config/finetune_tutorial_pbmc.yaml`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up data paths\n",
        "data_dir = \"/scratch/bioinf593f25_class_root/bioinf593f25_class/shared_data/themanifolds/tutorial_data\"\n",
        "annotation_dir = data_dir + '/annotation_dir'\n",
        "\n",
        "# Checkpoint path\n",
        "checkpoint_path = os.path.expanduser(\"~/grealakes/GETDiffusion.ckpt\")\n",
        "print(f\"Using checkpoint: {checkpoint_path}\")\n",
        "assert Path(checkpoint_path).exists(), f\"Checkpoint not found at {checkpoint_path}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure celltypes for modeling\n",
        "celltype_for_modeling = [\n",
        "    'memory_b',\n",
        "    'cd14_mono',\n",
        "    'gdt',\n",
        "    'cd8_tem_1',\n",
        "    'naive_b',\n",
        "    'mait',\n",
        "    'intermediate_b',\n",
        "    'cd4_naive',\n",
        "    'cd8_tem_2',\n",
        "    'cd8_naive',\n",
        "    'cd4_tem',\n",
        "    'cd4_tcm',\n",
        "    'cd16_mono',\n",
        "    'nk',\n",
        "    'cdc',\n",
        "    'treg'\n",
        "]\n",
        "\n",
        "# Load the predefined finetune tutorial config\n",
        "cfg = load_config('finetune_tutorial_pbmc')\n",
        "cfg.stage = 'fit'\n",
        "cfg.run.project_name = 'finetune_pbmc10k_multiome_GETDiffusion'\n",
        "cfg.run.run_name = 'finetune_from_GETDiffusion_checkpoint'\n",
        "cfg.dataset.quantitative_atac = False  # We use binary ATAC signal for motif interpretation analysis\n",
        "cfg.dataset.zarr_path = f\"{annotation_dir}/pbmc10k_multiome.zarr\"\n",
        "cfg.dataset.celltypes = ','.join(celltype_for_modeling)\n",
        "cfg.dataset.leave_out_celltypes = 'cd4_tcm'  # Leave out celltype for evaluation\n",
        "cfg.finetune.checkpoint = checkpoint_path\n",
        "cfg.training.epochs = 20\n",
        "cfg.machine.codebase = PROJECT_ROOT\n",
        "cfg.machine.num_devices = 1  # use 0 for cpu training; >=1 for gpu training\n",
        "cfg.machine.batch_size = 8  # batch size for training\n",
        "cfg.machine.output_dir = f\"{data_dir}/output\"\n",
        "\n",
        "print(f\"Output path: {cfg.machine.output_dir}/{cfg.run.project_name}/{cfg.run.run_name}\")\n",
        "print(f\"Training for {cfg.training.epochs} epochs\")\n",
        "print(f\"Checkpoint: {cfg.finetune.checkpoint}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the config to a yaml file\n",
        "export_config(cfg, \"exported_finetune_GETDiffusion_config.yaml\")\n",
        "print(\"Configuration exported to exported_finetune_GETDiffusion_config.yaml\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the config from the yaml file\n",
        "cfg = load_config_from_yaml(\"exported_finetune_GETDiffusion_config.yaml\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Default checkpoint path is at: {cfg.machine.output_dir}/{cfg.run.project_name}/{cfg.run.run_name}/checkpoints/best.ckpt\")\n",
        "print(\"The `trainer.checkpoint_callback.best_model_path` variable will be updated to the checkpoint path after training\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
